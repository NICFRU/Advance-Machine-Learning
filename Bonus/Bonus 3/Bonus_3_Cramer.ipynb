{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikla\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nikla\\workspace\\Machine Learning DHBW\\Bonusaufgabe 2\\Advance-Machine-Learning\\Bonus\\Bonus 3\\Bonus_3_Cramer.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikla/workspace/Machine%20Learning%20DHBW/Bonusaufgabe%202/Advance-Machine-Learning/Bonus/Bonus%203/Bonus_3_Cramer.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nikla/workspace/Machine%20Learning%20DHBW/Bonusaufgabe%202/Advance-Machine-Learning/Bonus/Bonus%203/Bonus_3_Cramer.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms, utils\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nikla/workspace/Machine%20Learning%20DHBW/Bonusaufgabe%202/Advance-Machine-Learning/Bonus/Bonus%203/Bonus_3_Cramer.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskimage\u001b[39;00m \u001b[39mimport\u001b[39;00m io, transform\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikla/workspace/Machine%20Learning%20DHBW/Bonusaufgabe%202/Advance-Machine-Learning/Bonus/Bonus%203/Bonus_3_Cramer.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nikla/workspace/Machine%20Learning%20DHBW/Bonusaufgabe%202/Advance-Machine-Learning/Bonus/Bonus%203/Bonus_3_Cramer.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"archive/\"\n",
    "data_path = path + \"socal2.csv\"\n",
    "pics_path = path + \"socal2/socal_pics/\"\n",
    "df = pd.read_csv(data_path)\n",
    "prices = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>street</th>\n",
       "      <th>citi</th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1317 Van Buren Avenue</td>\n",
       "      <td>Salton City, CA</td>\n",
       "      <td>317</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1560</td>\n",
       "      <td>201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>124 C Street W</td>\n",
       "      <td>Brawley, CA</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>713</td>\n",
       "      <td>228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2304 Clark Road</td>\n",
       "      <td>Imperial, CA</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>273950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>755 Brawley Avenue</td>\n",
       "      <td>Brawley, CA</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2207 R Carrillo Court</td>\n",
       "      <td>Calexico, CA</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2547</td>\n",
       "      <td>385100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                 street             citi  n_citi  bed  bath  sqft  \\\n",
       "0         0  1317 Van Buren Avenue  Salton City, CA     317    3   2.0  1560   \n",
       "1         1         124 C Street W      Brawley, CA      48    3   2.0   713   \n",
       "2         2        2304 Clark Road     Imperial, CA     152    3   1.0   800   \n",
       "3         3     755 Brawley Avenue      Brawley, CA      48    3   1.0  1082   \n",
       "4         4  2207 R Carrillo Court     Calexico, CA      55    4   3.0  2547   \n",
       "\n",
       "    price  \n",
       "0  201900  \n",
       "1  228500  \n",
       "2  273950  \n",
       "3  350000  \n",
       "4  385100  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images:  15474\n"
     ]
    }
   ],
   "source": [
    "X_house_images=np.zeros((15474,64,64,3),dtype='uint32')\n",
    "cnt=0\n",
    "for i in range(15474):\n",
    "\n",
    "    sample=cv2.imread(pics_path+'/'+str(i)+'.jpg')\n",
    "    imgs=cv2.resize(sample,(64,64))\n",
    "  \n",
    "    X_house_images[cnt]=imgs\n",
    "    cnt+=1\n",
    "\n",
    "print(\"No. of images: \",cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "split = train_test_split(df, X_house_images, test_size=0.25, random_state=42)\n",
    "(Xatt_train,Xatt_test,Ximage_train,Ximage_test) = split\n",
    "\n",
    "y_train , y_test = Xatt_train['price'].values , Xatt_test['price'].values\n",
    "\n",
    "X1_train=Xatt_train[['n_citi','bed','bath','sqft']].values\n",
    "X2_train=Ximage_train\n",
    "X1_test=Xatt_test[['n_citi','bed','bath','sqft']].values\n",
    "X2_test=Ximage_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.110e+02, 3.000e+00, 2.000e+00, 2.502e+03],\n",
       "       [3.070e+02, 4.000e+00, 3.000e+00, 1.895e+03],\n",
       "       [7.800e+01, 4.000e+00, 3.000e+00, 1.573e+03],\n",
       "       ...,\n",
       "       [8.200e+01, 4.000e+00, 3.000e+00, 1.550e+03],\n",
       "       [1.930e+02, 3.000e+00, 2.000e+00, 1.534e+03],\n",
       "       [2.650e+02, 3.000e+00, 2.100e+00, 2.580e+03]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, img, y):\n",
    "        self.x = torch.tensor(x).float()\n",
    "        self.img = img\n",
    "        self.y = torch.tensor(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        img = self.img[idx]\n",
    "        img = transforms.functional.to_tensor(img.astype(np.uint8).reshape((64, 64, 3)))\n",
    "        return {'x': x, 'y': y, 'img': img}\n",
    "    \n",
    "BATCH_SIZE = 256    \n",
    "train_dataset = MyDataset(X1_train,X2_train, y_train)\n",
    "dataLoader_train = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True)\n",
    "\n",
    "test_dataset = MyDataset(X1_test,X2_test, y_test)\n",
    "dataLoader_test = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fc1eb4eb3d0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataLoader_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1560</td>\n",
       "      <td>201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>713</td>\n",
       "      <td>228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>800</td>\n",
       "      <td>273950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2547</td>\n",
       "      <td>385100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  n_citi  bed  bath  sqft   price\n",
       "0         0     317    3   2.0  1560  201900\n",
       "1         1      48    3   2.0   713  228500\n",
       "2         2     152    3   1.0   800  273950\n",
       "3         3      48    3   1.0  1082  350000\n",
       "4         4      55    4   3.0  2547  385100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['street']\n",
    "del df['citi']\n",
    "#del df['n_citi']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flatten): Sequential(\n",
      "    (0): AdaptiveMaxPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (final_fc): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5, 5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        self.flatten = torch.nn.Sequential(torch.nn.AdaptiveMaxPool2d(1), torch.nn.Flatten())\n",
    "        \n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_shape, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.final_fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128+64, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, img):\n",
    "        img = self.conv(img)\n",
    "        img = self.flatten(img) \n",
    "        x = self.fc(x)\n",
    "        combined = torch.cat((img, x), dim=1)\n",
    "        #combined = torch.cat((img.view(img.size(0), -1), x.view(x.size(0), -1)), dim=1)\n",
    "        #print(x.size(), img.size())\n",
    "        price = self.final_fc(combined)\n",
    "        return price\n",
    "    \n",
    "model = Model(4)\n",
    "print(model)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:39<23:58, 159.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10 finished with train loss: 525078970724.1739 and test loss: 207061161472.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:23<21:36, 162.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/10 finished with train loss: 110927604869.56522 and test loss: 107115519744.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [08:00<18:38, 159.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/10 finished with train loss: 99138941996.52174 and test loss: 101747551488.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [10:44<16:09, 161.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/10 finished with train loss: 98605530423.65218 and test loss: 99086805504.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [13:26<13:27, 161.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/10 finished with train loss: 96771056506.43478 and test loss: 100011087360.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [16:08<10:47, 161.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/10 finished with train loss: 95817108613.56522 and test loss: 101267421184.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [18:53<08:08, 162.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/10 finished with train loss: 95464652800.0 and test loss: 97971708160.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [21:33<05:24, 162.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8/10 finished with train loss: 95159813787.82608 and test loss: 99372399104.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [24:17<02:42, 162.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9/10 finished with train loss: 93755081505.39131 and test loss: 99780259328.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [26:53<00:00, 161.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/10 finished with train loss: 93853830544.69565 and test loss: 99534354944.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "n_epochs = 10\n",
    "print('started!')\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    train_batch_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(dataLoader_train):\n",
    "        x = batch[\"x\"]\n",
    "        img = batch[\"img\"]\n",
    "        y = batch[\"y\"]\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x = x, img = img)\n",
    "        loss = criterion(outputs[:,0], y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_batch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    test_batch_loss = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for step, batch in enumerate(dataLoader_test):\n",
    "            x = batch[\"x\"]\n",
    "            img = batch[\"img\"]\n",
    "            y = batch[\"y\"]\n",
    "            outputs = model(x = x, img = img)\n",
    "            loss = criterion(outputs[:,0], y)\n",
    "            test_batch_loss += loss.item()     \n",
    "\n",
    "    print('epoch {}/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs, train_batch_loss / len(dataLoader_train), test_batch_loss / len(dataLoader_test)))\n",
    "    \n",
    "torch.save(model.state_dict(), './model_two_input.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results :\n",
      "\n",
      "RSS : 380696832934998.3\n",
      "RSE : 313763.5903382174\n",
      "TSS : 560633939775361.56\n",
      "R Squared : 0.3209529321618695\n",
      "MSE : 98396700164.12643\n",
      "MAE : 229841.06415578962\n",
      "Accuracy with 10% : 0.18350995089170327\n",
      "\n",
      "Train Results :\n",
      "\n",
      "RSS : 1075644050759336.2\n",
      "RSE : 304473.250464067\n",
      "TSS : 1638210861992667.8\n",
      "R Squared : 0.3434031749423533\n",
      "MSE : 92687983693.1802\n",
      "MAE : 224996.14421450882\n",
      "Accuracy with 10% : 0.1912968548039638\n"
     ]
    }
   ],
   "source": [
    "def reg_report(true, pred, name='Test'):\n",
    "    print(\"\\n{} Results :\\n\".format(name))\n",
    "    print(\"RSS :\",sum((pred-true)**2))\n",
    "    print(\"RSE :\",math.sqrt(sum((pred-true)**2)*(1/(len(pred)-2))))\n",
    "    print(\"TSS :\",sum((true-true.mean())**2))\n",
    "    print(\"R Squared :\",1-(sum((pred-true)**2)/sum((true-true.mean())**2)))\n",
    "    print(\"MSE :\",((pred-true)**2).mean())\n",
    "    print('MAE :',(abs(pred-true)).mean())\n",
    "    print('Accuracy with 10% :', ((pred<=true*1.1) & (true*0.9<=pred)).mean())\n",
    "    \n",
    "\n",
    "def eval_report(y_train, pred_train,y_test, pred_test):\n",
    "    reg_report(y_train, pred_train, name='Train')\n",
    "    reg_report(y_test, pred_test, name='Test')\n",
    "    \n",
    "def res(dataLoader, name = 'Test'):  \n",
    "    trues = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(dataLoader):\n",
    "            x = batch[\"x\"]\n",
    "            img = batch[\"img\"]\n",
    "            y = batch[\"y\"]\n",
    "\n",
    "            outputs = model(x = x, img = img)\n",
    "\n",
    "            trues = trues + y.tolist()\n",
    "            preds = preds + outputs[:,0].tolist()\n",
    "\n",
    "\n",
    "    reg_report(true =  np.array(trues), pred = np.array(preds), name=name)\n",
    "\n",
    "res(dataLoader_test, name = 'Test')\n",
    "res(dataLoader_train, name = 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flatten): Sequential(\n",
      "    (0): AdaptiveMaxPool2d(output_size=1)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (final_fc): Sequential(\n",
      "    (0): Linear(in_features=192, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Netz(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Netz, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 9, kernel_size=5)\n",
    "        #self.flatten=nn.Sequential(nn.AdaptiveMaxPool2d(1), nn.Flatten())\n",
    "        self.fc1 = nn.Linear(input_shape, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(137, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, img):\n",
    "        img = self.conv1(img)\n",
    "        img = F.max_pool2d(img, 3)\n",
    "        img = F.relu(img)\n",
    "\n",
    "        img = self.conv2(img)\n",
    "        img = F.max_pool2d(img, 3)\n",
    "        img = F.relu(img)\n",
    "        #\n",
    "        # img=self.flatten(img)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        #rint(x.shape,img.shape)\n",
    "        #combined = torch.cat((img.view(img.size(0), -1), x.view(x.size(0), -1)), dim=1)\n",
    "        combined = torch.cat((x, img), 1)\n",
    "        price = self.fc3(combined)\n",
    "        return price\n",
    "        #pass\n",
    "\n",
    "model_2 = Netz(4)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [119], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m y \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[39m=\u001b[39m model_2(x \u001b[39m=\u001b[39;49m x, img \u001b[39m=\u001b[39;49m img)\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs[:,\u001b[39m0\u001b[39m], y)\n\u001b[1;32m     16\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [118], line 29\u001b[0m, in \u001b[0;36mNetz.forward\u001b[0;34m(self, x, img)\u001b[0m\n\u001b[1;32m     26\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     27\u001b[0m \u001b[39m#rint(x.shape,img.shape)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m#combined = torch.cat((img.view(img.size(0), -1), x.view(x.size(0), -1)), dim=1)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m combined \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat((x, img), \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     30\u001b[0m price \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(combined)\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m price\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 4"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "n_epochs = 10\n",
    "print('started!')\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    train_batch_loss = 0\n",
    "    model_2.train()\n",
    "    for step, batch in enumerate(dataLoader_train):\n",
    "        x = batch[\"x\"]\n",
    "        img = batch[\"img\"]\n",
    "        y = batch[\"y\"]\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_2(x = x, img = img)\n",
    "        loss = criterion(outputs[:,0], y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_batch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    test_batch_loss = 0\n",
    "    model_2.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "         for step, batch in enumerate(dataLoader_test):\n",
    "            x = batch[\"x\"]\n",
    "            img = batch[\"img\"]\n",
    "            y = batch[\"y\"]\n",
    "            outputs = model_2(x = x, img = img)\n",
    "            loss = criterion(outputs[:,0], y)\n",
    "            test_batch_loss += loss.item()     \n",
    "\n",
    "    print('epoch {}/{} finished with train loss: {} and test loss: {}'.format(epoch+1, n_epochs, train_batch_loss / len(dataLoader_train), test_batch_loss / len(dataLoader_test)))\n",
    "    \n",
    "torch.save(model_2.state_dict(), './mmodel_2odel_two_input.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results :\n",
      "\n",
      "RSS : 2488957288173446.0\n",
      "RSE : 802272.0013507858\n",
      "TSS : 560633939775360.8\n",
      "R Squared : -3.439540868986171\n",
      "MSE : 643307647498.9537\n",
      "MAE : 705963.4366304198\n",
      "Accuracy with 10% : 0.0\n",
      "\n",
      "Train Results :\n",
      "\n",
      "RSS : 7362237494844666.0\n",
      "RSE : 796562.3317061164\n",
      "TSS : 1638210861992678.0\n",
      "R Squared : -3.4940719571895817\n",
      "MSE : 634402196884.5054\n",
      "MAE : 702295.735096819\n",
      "Accuracy with 10% : 0.0\n"
     ]
    }
   ],
   "source": [
    "def reg_report(true, pred, name='Test'):\n",
    "    print(\"\\n{} Results :\\n\".format(name))\n",
    "    print(\"RSS :\",sum((pred-true)**2))\n",
    "    print(\"RSE :\",math.sqrt(sum((pred-true)**2)*(1/(len(pred)-2))))\n",
    "    print(\"TSS :\",sum((true-true.mean())**2))\n",
    "    print(\"R Squared :\",1-(sum((pred-true)**2)/sum((true-true.mean())**2)))\n",
    "    print(\"MSE :\",((pred-true)**2).mean())\n",
    "    print('MAE :',(abs(pred-true)).mean())\n",
    "    print('Accuracy with 10% :', ((pred<=true*1.1) & (true*0.9<=pred)).mean())\n",
    "    \n",
    "\n",
    "def eval_report(y_train, pred_train,y_test, pred_test):\n",
    "    reg_report(y_train, pred_train, name='Train')\n",
    "    reg_report(y_test, pred_test, name='Test')\n",
    "    \n",
    "def res(dataLoader, name = 'Test'):  \n",
    "    trues = []\n",
    "    preds = []\n",
    "    model_2.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(dataLoader):\n",
    "            x = batch[\"x\"]\n",
    "            img = batch[\"img\"]\n",
    "            y = batch[\"y\"]\n",
    "\n",
    "            outputs = model_2(x = x, img = img)\n",
    "\n",
    "            trues = trues + y.tolist()\n",
    "            preds = preds + outputs[:,0].tolist()\n",
    "\n",
    "\n",
    "    reg_report(true =  np.array(trues), pred = np.array(preds), name=name)\n",
    "\n",
    "res(dataLoader_test, name = 'Test')\n",
    "res(dataLoader_train, name = 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoInputsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoInputsNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(3,8,kernel_size=3) \n",
    "        self.conv1 = nn.Conv2d(8,8,kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(8,8,kernel_size=3) \n",
    "        self.fc1 = nn.Linear(3,3)\n",
    "        self.fc2 = nn.Linear(26915,1024)\n",
    "        self.fc3 = nn.Linear(1024,32) \n",
    "        self.fc4 = nn.Linear(32,1) \n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        c = self.conv(input1)\n",
    "        c = self.conv1(c)\n",
    "        c = F.relu(c)\n",
    "        c = self.conv2(c)\n",
    "        c = F.relu(c)\n",
    "        f = self.fc1(input2)\n",
    "        # now we can reshape `c` and `f` to 2D and concat them\n",
    "        #combined = torch.cat((c.view(c.size(0), -1), f.view(f.size(0), -1)), dim=1)\n",
    "        combined = torch.cat((img, x), dim=1)\n",
    "        out = self.fc2(combined)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc4(out)\n",
    "\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoInputsNet(\n",
      "  (conv): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (fc2): Linear(in_features=26915, out_features=1024, bias=True)\n",
      "  (fc3): Linear(in_features=1024, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = TwoInputsNet()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "n_epochs = 10\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,momentum=momentum)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,epoch):\n",
    "    batch_idx = 0\n",
    "    for items in dataloader:\n",
    "        image = torch.FloatTensor(batch['img'])\n",
    "        features = torch.FloatTensor(items['x'])\n",
    "        price = torch.FloatTensor(items['y'])\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.cuda()\n",
    "            features = features.cuda()\n",
    "            price = price.cuda()\n",
    "            \n",
    "        output = network(image,features)\n",
    "        output = output.reshape(4)\n",
    "        loss = loss_func(output, price)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 4 == 0: #every 25 * batchsize sample we print results\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch+1, batch_idx * image.shape[0], len(dataloader.dataset),\n",
    "            100. * batch_idx / len(dataloader), loss.item()))\n",
    "            \n",
    "        batch_idx = batch_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x4 and 3x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [134], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# train \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     train(train_dataset,epoch)\n",
      "Cell \u001b[0;32mIn [133], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     11\u001b[0m     price \u001b[39m=\u001b[39m price\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> 13\u001b[0m output \u001b[39m=\u001b[39m network(image,features)\n\u001b[1;32m     14\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mreshape(\u001b[39m4\u001b[39m)\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m loss_func(output, price)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [130], line 18\u001b[0m, in \u001b[0;36mTwoInputsNet.forward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     16\u001b[0m c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(c)\n\u001b[1;32m     17\u001b[0m c \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(c)\n\u001b[0;32m---> 18\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(input2)\n\u001b[1;32m     19\u001b[0m \u001b[39m# now we can reshape `c` and `f` to 2D and concat them\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m#combined = torch.cat((c.view(c.size(0), -1), f.view(f.size(0), -1)), dim=1)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m combined \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((img, x), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x4 and 3x3)"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # train \n",
    "    train(train_dataset,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.926382</td>\n",
       "      <td>0.996177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.975096</td>\n",
       "      <td>0.981440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.632850</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970093</td>\n",
       "      <td>0.956260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953874</td>\n",
       "      <td>0.914127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.867150</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.869615</td>\n",
       "      <td>0.894681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id    n_citi  bed  bath      sqft     price\n",
       "0         0  0.234300    3   2.0  0.926382  0.996177\n",
       "1         1  0.884058    3   2.0  0.975096  0.981440\n",
       "2         2  0.632850    3   1.0  0.970093  0.956260\n",
       "3         3  0.884058    3   1.0  0.953874  0.914127\n",
       "4         4  0.867150    4   3.0  0.869615  0.894681"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>n_citi</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>sqft</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10305</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.895439</td>\n",
       "      <td>0.693629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7918</td>\n",
       "      <td>0.328502</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.938805</td>\n",
       "      <td>0.582271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8316</td>\n",
       "      <td>0.236715</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.949272</td>\n",
       "      <td>0.994460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6262</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.855984</td>\n",
       "      <td>0.858726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1938</td>\n",
       "      <td>0.321256</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.952091</td>\n",
       "      <td>0.803380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id    n_citi  bed  bath      sqft     price\n",
       "0     10305  0.811594    4   2.1  0.895439  0.693629\n",
       "1      7918  0.328502    2   2.0  0.938805  0.582271\n",
       "2      8316  0.236715    3   2.0  0.949272  0.994460\n",
       "3      6262  0.016908    4   3.0  0.855984  0.858726\n",
       "4      1938  0.321256    3   2.0  0.952091  0.803380"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(256)\n",
    "df.reset_index(inplace = True )\n",
    "del df['index']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'street'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'street'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [226], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdel\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mstreet\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[39mdel\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mciti\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m cols \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39msqft\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprice\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mn_citi\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/pandas/core/generic.py:4243\u001b[0m, in \u001b[0;36mNDFrame.__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4238\u001b[0m             deleted \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   4239\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m deleted:\n\u001b[1;32m   4240\u001b[0m     \u001b[39m# If the above loop ran and didn't delete anything because\u001b[39;00m\n\u001b[1;32m   4241\u001b[0m     \u001b[39m# there was no match, this call should raise the appropriate\u001b[39;00m\n\u001b[1;32m   4242\u001b[0m     \u001b[39m# exception:\u001b[39;00m\n\u001b[0;32m-> 4243\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4244\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39midelete(loc)\n\u001b[1;32m   4246\u001b[0m \u001b[39m# delete from the caches\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Bonu_Aufgaben/lib/python3.8/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'street'"
     ]
    }
   ],
   "source": [
    "del df['street']\n",
    "del df['citi']\n",
    "for cols in ['sqft','price','n_citi']:\n",
    "    df[cols] = (df[cols].max() - df[cols])/(df[cols].max() - df[cols].min())\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SocalDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.features = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        try:\n",
    "            img_name = '{}{}.jpg'.format(str(self.root_dir), str(self.features.loc[idx,'image_id']))\n",
    "            image = io.imread(img_name)\n",
    "            image = image / 255.0\n",
    "        \n",
    "            if len(image.shape) == 3:\n",
    "                house_features = self.features.iloc[idx, 1:]\n",
    "                house_features = np.array([house_features]).reshape(5)\n",
    "                sample = {'image': image, 'house_features': house_features}\n",
    "\n",
    "                if self.transform:\n",
    "                    sample['image'] = transform.resize(sample['image'],(64,64)).reshape(3,64,64)\n",
    "                    \n",
    "                sample['image'] = torch.from_numpy(sample['image']).float()\n",
    "                sample['house_features'] = torch.from_numpy(sample['house_features']).float()\n",
    "\n",
    "                return sample\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_dataset = SocalDataset(dataframe=df,\n",
    "                            root_dir=pics_path,\n",
    "                            transform = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "1 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "2 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "3 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "4 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "5 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "6 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "7 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "8 torch.Size([3, 64, 64]) torch.Size([5])\n",
      "9 torch.Size([3, 64, 64]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sample = house_dataset[i]\n",
    "    print(i, sample['image'].shape, sample['house_features'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "\n",
    "test_amount = int(house_dataset.__len__() * test_size)\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(house_dataset,[\n",
    "            (house_dataset.__len__() - test_amount ), test_amount ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=5,\n",
    "            shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=5,\n",
    "            shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "it = iter(train_dataloader)\n",
    "items = next(it)\n",
    "print(type(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 64, 64])\n",
      "torch.Size([5, 5])\n",
      "tensor([[0.8019, 3.0000, 3.0000, 0.9127, 0.9668],\n",
      "        [0.8744, 2.0000, 1.0000, 0.9431, 0.6931],\n",
      "        [0.3599, 2.0000, 1.0000, 0.9435, 0.7618],\n",
      "        [0.5338, 3.0000, 2.0000, 0.9416, 0.9778],\n",
      "        [0.4372, 3.0000, 2.1000, 0.9174, 0.8643]])\n"
     ]
    }
   ],
   "source": [
    "print(items['image'].shape)\n",
    "print(items['house_features'].shape)\n",
    "print(items['house_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoInputsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoInputsNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(3,6,kernel_size=3) \n",
    "        self.conv1 = nn.Conv2d(6,9,kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(9,12,kernel_size=3) \n",
    "        self.fc1 = nn.Linear(4,3)\n",
    "        self.fc2 = nn.Linear(40371,1024)\n",
    "        self.fc3 = nn.Linear(1024,32) \n",
    "        self.fc4 = nn.Linear(32,1) \n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        c = self.conv(input1)\n",
    "        c = self.conv1(c)\n",
    "        c = F.relu(c)\n",
    "        c = self.conv2(c)\n",
    "        c = F.relu(c)\n",
    "        f = self.fc1(input2)\n",
    "        \n",
    "        # now we can reshape `c` and `f` to 2D and concat them\n",
    "        combined = torch.cat((c.view(c.size(0), -1),\n",
    "                          f.view(f.size(0), -1)), dim=1)\n",
    "        out = self.fc2(combined)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc4(out)\n",
    "\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoInputsNet(\n",
      "  (conv): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv1): Conv2d(6, 9, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(9, 12, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (fc2): Linear(in_features=40371, out_features=1024, bias=True)\n",
      "  (fc3): Linear(in_features=1024, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = TwoInputsNet()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "n_epochs = 5\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,momentum=momentum)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_set,\n",
    "            batch_size=5,\n",
    "            shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=5,\n",
    "            shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,epoch):\n",
    "    batch_idx = 0\n",
    "    for items in dataloader:\n",
    "        image = torch.FloatTensor(items['image'])\n",
    "        features = torch.FloatTensor(items['house_features'][:,:4])\n",
    "        price = torch.FloatTensor(items['house_features'][:,4])\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.cuda()\n",
    "            features = features.cuda()\n",
    "            price = price.cuda()\n",
    "            \n",
    "        output = network(image,features)\n",
    "        output = output.reshape(5)\n",
    "        loss = loss_func(output, price)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 4 == 0: #every 25 * batchsize sample we print results\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch+1, batch_idx * image.shape[0], len(dataloader.dataset),\n",
    "            100. * batch_idx / len(dataloader), loss.item()))\n",
    "            \n",
    "        batch_idx = batch_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/180 (0%)]\tLoss: 0.452995\n",
      "Train Epoch: 1 [20/180 (11%)]\tLoss: 0.126921\n",
      "Train Epoch: 1 [40/180 (22%)]\tLoss: 0.093897\n",
      "Train Epoch: 1 [60/180 (33%)]\tLoss: 0.059054\n",
      "Train Epoch: 1 [80/180 (44%)]\tLoss: 0.018912\n",
      "Train Epoch: 1 [100/180 (56%)]\tLoss: 0.026393\n",
      "Train Epoch: 1 [120/180 (67%)]\tLoss: 0.073876\n",
      "Train Epoch: 1 [140/180 (78%)]\tLoss: 0.019582\n",
      "Train Epoch: 1 [160/180 (89%)]\tLoss: 0.071252\n",
      "Train Epoch: 2 [0/180 (0%)]\tLoss: 0.009247\n",
      "Train Epoch: 2 [20/180 (11%)]\tLoss: 0.005556\n",
      "Train Epoch: 2 [40/180 (22%)]\tLoss: 0.057850\n",
      "Train Epoch: 2 [60/180 (33%)]\tLoss: 0.207975\n",
      "Train Epoch: 2 [80/180 (44%)]\tLoss: 0.030397\n",
      "Train Epoch: 2 [100/180 (56%)]\tLoss: 0.086041\n",
      "Train Epoch: 2 [120/180 (67%)]\tLoss: 0.005431\n",
      "Train Epoch: 2 [140/180 (78%)]\tLoss: 0.035753\n",
      "Train Epoch: 2 [160/180 (89%)]\tLoss: 0.133349\n",
      "Train Epoch: 3 [0/180 (0%)]\tLoss: 0.015860\n",
      "Train Epoch: 3 [20/180 (11%)]\tLoss: 0.035526\n",
      "Train Epoch: 3 [40/180 (22%)]\tLoss: 0.020284\n",
      "Train Epoch: 3 [60/180 (33%)]\tLoss: 0.011326\n",
      "Train Epoch: 3 [80/180 (44%)]\tLoss: 0.131106\n",
      "Train Epoch: 3 [100/180 (56%)]\tLoss: 0.052148\n",
      "Train Epoch: 3 [120/180 (67%)]\tLoss: 0.026631\n",
      "Train Epoch: 3 [140/180 (78%)]\tLoss: 0.043114\n",
      "Train Epoch: 3 [160/180 (89%)]\tLoss: 0.045804\n",
      "Train Epoch: 4 [0/180 (0%)]\tLoss: 0.101069\n",
      "Train Epoch: 4 [20/180 (11%)]\tLoss: 0.044998\n",
      "Train Epoch: 4 [40/180 (22%)]\tLoss: 0.021710\n",
      "Train Epoch: 4 [60/180 (33%)]\tLoss: 0.131808\n",
      "Train Epoch: 4 [80/180 (44%)]\tLoss: 0.060891\n",
      "Train Epoch: 4 [100/180 (56%)]\tLoss: 0.026389\n",
      "Train Epoch: 4 [120/180 (67%)]\tLoss: 0.022358\n",
      "Train Epoch: 4 [140/180 (78%)]\tLoss: 0.061502\n",
      "Train Epoch: 4 [160/180 (89%)]\tLoss: 0.013414\n",
      "Train Epoch: 5 [0/180 (0%)]\tLoss: 0.036915\n",
      "Train Epoch: 5 [20/180 (11%)]\tLoss: 0.067229\n",
      "Train Epoch: 5 [40/180 (22%)]\tLoss: 0.020201\n",
      "Train Epoch: 5 [60/180 (33%)]\tLoss: 0.048129\n",
      "Train Epoch: 5 [80/180 (44%)]\tLoss: 0.056789\n",
      "Train Epoch: 5 [100/180 (56%)]\tLoss: 0.161134\n",
      "Train Epoch: 5 [120/180 (67%)]\tLoss: 0.017697\n",
      "Train Epoch: 5 [140/180 (78%)]\tLoss: 0.057869\n",
      "Train Epoch: 5 [160/180 (89%)]\tLoss: 0.024027\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # train \n",
    "    train(train_dataloader,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results :\n",
      "\n",
      "RSS : 6.53765385536986\n",
      "RSE : 0.19164652996049286\n",
      "TSS : 6.631032657354906\n",
      "R Squared : 0.014082090499354383\n",
      "MSE : 0.03632029919649922\n",
      "MAE : 0.13936191845441656\n",
      "Accuracy with 10% : 0.35555555555555557\n",
      "\n",
      "Train Results :\n",
      "\n",
      "RSS : 3.6185278102910923\n",
      "RSE : 0.22113123809944435\n",
      "TSS : 3.641416601597961\n",
      "R Squared : 0.006285683241193718\n",
      "MSE : 0.047612208030145944\n",
      "MAE : 0.16736403372334807\n",
      "Accuracy with 10% : 0.27631578947368424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def reg_report(true, pred, name='Test'):\n",
    "    print(\"\\n{} Results :\\n\".format(name))\n",
    "    print(\"RSS :\",sum((pred-true)**2))\n",
    "    print(\"RSE :\",math.sqrt(sum((pred-true)**2)*(1/(len(pred)-2))))\n",
    "    print(\"TSS :\",sum((true-true.mean())**2))\n",
    "    print(\"R Squared :\",1-(sum((pred-true)**2)/sum((true-true.mean())**2)))\n",
    "    print(\"MSE :\",((pred-true)**2).mean())\n",
    "    print('MAE :',(abs(pred-true)).mean())\n",
    "    print('Accuracy with 10% :', ((pred<=true*1.1) & (true*0.9<=pred)).mean())\n",
    "    \n",
    "\n",
    "def eval_report(y_train, pred_train,y_test, pred_test):\n",
    "    reg_report(y_train, pred_train, name='Train')\n",
    "    reg_report(y_test, pred_test, name='Test')\n",
    "    \n",
    "def res(dataLoader, name = 'Test'):  \n",
    "    trues = []\n",
    "    preds = []\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        for items in dataLoader:\n",
    "            image = torch.FloatTensor(items['image'])\n",
    "            features = torch.FloatTensor(items['house_features'][:,:4])\n",
    "            price = torch.FloatTensor(items['house_features'][:,4])\n",
    "\n",
    "            outputs = network(input2 = features, input1 = image)\n",
    "\n",
    "            trues = trues + price.tolist()\n",
    "            preds = preds + outputs[:,0].tolist()\n",
    "\n",
    "\n",
    "    reg_report(true =  np.array(trues), pred = np.array(preds), name=name)\n",
    "\n",
    "res(train_dataloader, name = 'Test')\n",
    "res(test_dataloader, name = 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cde137ca4d604021dfeee5cc69f15444c7734737e8b71c16850c523803c8f980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
